ðŸŽ¯ Tool Features

1. Download â€” Download files from given URLs concurrently
2. Compress â€” Compress files using gzip
3. Analyze â€” Parse log files to extract metrics (like request count, error rate)


ðŸ§ª Sample Commands

# Download files from urls.txt
go run main.go download -input=urls.txt -out=downloads/

# Compress all files in folder
go run main.go compress -dir=downloads/

# Analyze a log file
go run main.go analyze -file=server.log


ðŸ“š DOCS: 
1. CLI arguments: https://gobyexample.com/command-line-arguments
2. CLI flags: https://gobyexample.com/command-line-flags
3. CLI subcommands: https://gobyexample.com/command-line-subcommands

ðŸ•› Tools:
1. Resume failed downloads, monitor etc: https://github.com/cavaliergopher/grab

Improvements
1. Lack of concurrency limits
You're launching 100s of goroutines if there are 100s of URLs. This can overload your system/network.

âœ… Fix: Use a buffered channel as a semaphore (optional improvement, I can help later)