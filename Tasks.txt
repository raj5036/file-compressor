ğŸ¯ Tool Features

1. Download â€” Download files from given URLs concurrently
2. Compress â€” Compress files using gzip
3. Analyze â€” Parse log files to extract metrics (like request count, error rate)


ğŸ§ª Sample Commands

# Download files from urls.txt
go run . download -input="urls.txt" -output=downloads/ -analyze=true

# Compress all files in folder
go run . compress -input=downloads/ -output=compressed.tar.gz

# Analyze a log file
go run . analyze -file=server.log


ğŸ“š DOCS: 
1. CLI arguments: https://gobyexample.com/command-line-arguments
2. CLI flags: https://gobyexample.com/command-line-flags
3. CLI subcommands: https://gobyexample.com/command-line-subcommands

ğŸ•› Tools:
1. Resume failed downloads, monitor etc: https://github.com/cavaliergopher/grab

â¬†ï¸ Improvements
1. Lack of concurrency limits
You're launching 100s of goroutines if there are 100s of URLs. This can overload your system/network.
Fix: Use a buffered channel as a semaphore (optional improvement, I can help later)

âœ… Todo
1. Remove main.exe and Tasks.txt from version control