🎯 Tool Features

1. Download — Download files from given URLs concurrently
2. Compress — Compress files using gzip
3. Analyze — Parse log files to extract metrics (like request count, error rate)


🧪 Sample Commands

# Download files from urls.txt
go run . download -input="urls.txt" -output=downloads/ -analyze=true

# Compress all files in folder
go run . compress -input=downloads/ -output=compressed.tar.gz

# Analyze a log file
go run . analyze -file=server.log


📚 DOCS: 
1. CLI arguments: https://gobyexample.com/command-line-arguments
2. CLI flags: https://gobyexample.com/command-line-flags
3. CLI subcommands: https://gobyexample.com/command-line-subcommands

🕛 Tools:
1. Resume failed downloads, monitor etc: https://github.com/cavaliergopher/grab

⬆️ Improvements
1. Lack of concurrency limits
You're launching 100s of goroutines if there are 100s of URLs. This can overload your system/network.
Fix: Use a buffered channel as a semaphore (optional improvement, I can help later)

✅ Todo
1. Remove main.exe and Tasks.txt from version control